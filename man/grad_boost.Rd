% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gradient_boosting.R
\name{grad_boost}
\alias{grad_boost}
\title{Fit a boosted linear model}
\usage{
grad_boost(formula, data, nu = 0.01, stop, grad.fun, loss.fun, yhat.init = 0)
}
\arguments{
\item{formula}{an object of class formula}

\item{data}{a data.frame or matrix}

\item{nu}{a numeric within the range of \link{0,1}, the learning rate}

\item{stop}{a numeric value determining the total boosting iterations}

\item{grad.fun}{a function which computes the gradient of the loss function}

\item{loss.fun}{a convex loss function which is continuously differentiable}

\item{yhat.init}{a numeric value determining the starting point}
}
\value{
\itemize{
\item theta - this is our estimator
\item u - this is the last gradient value
\item fit - our fitted values, i.e. X \%*\% theta
\item formula - the underlying formula
\item data - the underlying data
}
}
\description{
Fit a boosted linear model
}
\examples{
# Complete runthrough see: www.github.com/andrebleier/cheapml
# Gradient Boosting Runthrough --------------------------------------------

# load data simulation tool
# library(devtools)
# devtools::install_github('andrebleier/Xy')
library(Xy)

# simulate data
sim <- Xy(n = 1000, # 1000 observations
        numvars = c(2, 0), # 2 linear variables / 0 nonlinear
        noisevars = 0, # no noise variables
        catvars = 0, # omit dummy variables
        stn = 30, # signal to noise ratio 30:1
        intercept = TRUE
        )

# simulation overview
sim

# get the formula
eq <- sim$eq

# get the formula
model_df <- sim$data

# source the function
source("algorithms/grad_boost.R")

# fit
mod <- grad_boost(formula = eq, data = model_df,
                 nu = 0.1, stop = 100,
                 grad.fun = gradient,
                 loss.fun = loss)

# our estimator
mod$theta

# the true underlying effect
coef(sim)

}
